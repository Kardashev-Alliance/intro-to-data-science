{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6050aa-95cc-4bdf-a6bf-d07559196658",
   "metadata": {},
   "source": [
    "# Module 6: Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c49fa4-b61f-4239-81b9-a38ab8a4d926",
   "metadata": {},
   "source": [
    "## 1. EDA Fundamentals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c374d38f-26fc-4aa0-9271-cd85d1e77d29",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA) is a crucial step in the data analysis process. It involves the initial examination and exploration of a dataset to understand its key characteristics and gain insights into the data. EDA helps data scientists and analysts make informed decisions about data cleaning, feature engineering, and the choice of modeling techniques.\n",
    "\n",
    "**Major Components of EDA**\n",
    "\n",
    "EDA typically consists of the following major components:\n",
    "\n",
    "1. **Data Collection**: Gathering the dataset from various sources, such as databases, APIs, or public datasets like the Titanic dataset loaded in the code above.\n",
    "\n",
    "2. **Data Cleaning**: Identifying and handling missing values, outliers, and any inconsistencies in the data. This step ensures that the dataset is suitable for analysis.\n",
    "\n",
    "3. **Data Visualization**: Creating visualizations, such as histograms, scatter plots, and box plots, to understand the distribution of data, relationships between variables, and potential patterns.\n",
    "\n",
    "4. **Summary Statistics**: Calculating summary statistics, including measures like mean, median, standard deviation, and percentiles, to describe the central tendency and variability of the data.\n",
    "\n",
    "5. **Feature Engineering**: Creating new features or transforming existing ones to enhance the dataset's information content and improve model performance.\n",
    "\n",
    "6. **Hypothesis Testing**: Formulating hypotheses about the data and conducting statistical tests to validate or reject these hypotheses.\n",
    "\n",
    "7. **Correlation Analysis**: Examining the relationships between variables, often using correlation coefficients, to identify dependencies.\n",
    "\n",
    "8. **Dimensionality Reduction**: Reducing the number of variables or features through techniques like Principal Component Analysis (PCA) or feature selection methods.\n",
    "\n",
    "9. **Data Reporting**: Communicating the findings and insights from the EDA process through reports, visualizations, and presentations.\n",
    "\n",
    "10. **Iterative Process**: EDA is often an iterative process, where data analysts revisit previous steps as they gain more insights and refine their understanding of the dataset.\n",
    "\n",
    "Overall, EDA plays a crucial role in setting the stage for subsequent data analysis tasks, such as machine learning model building, and helps in making data-driven decisions. It allows data professionals to uncover patterns, detect anomalies, and generate hypotheses about the data using real-world datasets like the Titanic dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac31b3d-1dfe-4d04-97c8-79c6e1a2d8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, we will need to load a public dataset to conduct EDA\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset for EDA\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset to get an overview\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dfbbe3-d7a0-472d-bfbd-7ae6ff9c085d",
   "metadata": {},
   "source": [
    "## 2. Summary Statistics and Descriptive Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5940d03-0855-4e36-bf70-db01894ebcfd",
   "metadata": {},
   "source": [
    "**Summary Statistics and Descriptive Analysis in the Titanic Dataset**\n",
    "\n",
    "Summary statistics and descriptive analysis are fundamental techniques used to explore datasets and understand their key characteristics. In this code example, we'll apply these concepts to the Titanic dataset, which contains information about passengers on the Titanic.\n",
    "\n",
    "**When and why is it used?**\n",
    "\n",
    "- **When**: Summary statistics and descriptive analysis are typically the first steps in the exploratory data analysis (EDA) process. They are used at the beginning of data analysis to gain initial insights into the dataset.\n",
    "\n",
    "- **Why**: Here are the primary reasons for using summary statistics and descriptive analysis in the Titanic dataset:\n",
    "\n",
    "  1. **Data Understanding**: To get a sense of the data's overall structure, such as the number of rows and columns, as well as the initial values.\n",
    "\n",
    "  2. **Basic Statistics**: To compute key statistics for numeric columns, such as measures of central tendency (mean, median), dispersion (standard deviation), and quartiles.\n",
    "\n",
    "  3. **Categorical Data**: To count unique values and understand the distribution of categorical columns.\n",
    "\n",
    "  4. **Correlation Analysis**: To calculate the correlation matrix for numeric columns, helping identify potential relationships between variables.\n",
    "\n",
    "**Necessary Information for Summary Statistics and Descriptive Analysis in the Titanic Dataset**:\n",
    "\n",
    "1. **Summary Statistics**: We use the `describe()` function to obtain key statistics for numeric columns:\n",
    "   - **Count**: Number of non-null observations.\n",
    "   - **Mean**: Average value.\n",
    "   - **Std**: Standard deviation.\n",
    "   - **Min**: Minimum value.\n",
    "   - **25%**: First quartile (25th percentile).\n",
    "   - **50%**: Median (50th percentile).\n",
    "   - **75%**: Third quartile (75th percentile).\n",
    "   - **Max**: Maximum value.\n",
    "\n",
    "2. **Categorical Data**: We count unique values in categorical columns using a loop. This helps us understand the variety within these columns.\n",
    "\n",
    "3. **Correlation Analysis**: We compute the correlation matrix to identify relationships between numeric columns. A correlation matrix shows how pairs of variables are related.\n",
    "\n",
    "By performing summary statistics and descriptive analysis, we can quickly grasp important characteristics of the Titanic dataset, such as basic statistics and potential correlations. These initial insights provide a foundation for further analysis and modeling.\n",
    "\n",
    "Summary statistics are often followed by data visualization to gain deeper insights into the data's patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdf184-45aa-4d68-8191-f1ec8efb26a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset for EDA\n",
    "url = 'https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset to get an overview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35188393-3413-4f09-ba26-b301f699be7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating summary statistics for the Titanic dataset\n",
    "summary_stats = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5d2d9-95b2-440b-9171-a6813a06ceec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f43b54-13c6-4c99-b190-897de2d1fb87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count unique values in categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    unique_values = df[col].nunique()\n",
    "    print(f\"Unique {col}: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ece2c6-9d6a-46e0-8102-628e948ae337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for numeric columns\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daadea8-5424-466c-b630-1b1d4df1415b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the correlation matrix\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f0412c-5951-45e5-9e9f-7b18d4e7fdb1",
   "metadata": {},
   "source": [
    "**Inverse Relationship: Survived vs. Pclass**\n",
    "\n",
    "In the Titanic dataset, \"Pclass\" represents the passenger class, where 1st class is the highest and 3rd class is the lowest. On the other hand, \"Survived\" indicates whether a passenger survived (1) or did not survive (0).\n",
    "\n",
    "The inverse relationship is due to the fact that lower passenger classes (e.g., 3rd class) were associated with a lower chance of survival, while higher passenger classes (e.g., 1st class) had a higher chance of survival. This inverse relationship means that as \"Pclass\" increases (from 3rd class to 1st class), the likelihood of survival also increases. In other words, passengers in 1st class had a better chance of surviving compared to those in 3rd class.\n",
    "\n",
    "This can be summarized as follows:\n",
    "\n",
    "- 1st Class (higher \"Pclass\") → Higher Chance of Survival\n",
    "- 3rd Class (lower \"Pclass\") → Lower Chance of Survival\n",
    "\n",
    "The correlation coefficient quantifies this relationship and is negative, indicating the inverse relationship between \"Survived\" and \"Pclass.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487dd661-32dd-45ae-aa00-aa31432c5eb6",
   "metadata": {},
   "source": [
    "## 3. Distribution Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c453c-05b0-4c28-add1-96795bb6623d",
   "metadata": {},
   "source": [
    "Distribution analysis is a crucial component of exploratory data analysis (EDA). It involves examining how data points are spread or distributed within a dataset. This analysis helps us understand the central tendency (mean, median, mode) and the spread or variability of the data. Histograms are a common visualization tool for distribution analysis.\n",
    "\n",
    "**In the provided Python code example:**\n",
    "\n",
    "- We start by loading the Titanic dataset, which contains various passenger information, using the Pandas library.\n",
    "\n",
    "- Next, we extract the \"Age\" column from the dataset, which represents the ages of Titanic passengers. This column is stored in the variable `ages`.\n",
    "\n",
    "- We create a histogram using the Matplotlib library with `plt.hist()`. Here are the key parameters used:\n",
    "  - `ages`: The data to be plotted, which is the passenger ages.\n",
    "  - `bins=10`: Specifies that we want the data divided into 10 bins or intervals.\n",
    "  - `edgecolor='k'`: Adds black borders to the histogram bars for clarity.\n",
    "  - `alpha=0.7`: Sets the transparency of the bars to 0.7 for a smoother appearance.\n",
    "  - `color='skyblue'`: Defines the color of the bars as sky blue.\n",
    "\n",
    "- We include a title on the plot using `plt.title()` to indicate that we are visualizing the distribution of passenger ages.\n",
    "\n",
    "- The x-axis is labeled as 'Age' with `plt.xlabel()`, and the y-axis is labeled as 'Frequency' with `plt.ylabel()`.\n",
    "\n",
    "- We add a grid along the y-axis using `plt.grid()` to improve readability and facilitate interpreting the frequencies.\n",
    "\n",
    "- To provide a summary statistic reference, a vertical dashed red line is drawn at the mean age using `plt.axvline()`. This line helps us see where the mean age falls within the distribution.\n",
    "\n",
    "- A legend is included with `plt.legend()` to label the mean age line as 'Mean Age' and position it in the upper right corner.\n",
    "\n",
    "Running this code generates a histogram that visually represents the distribution of passenger ages in the Titanic dataset. The histogram allows us to observe the central tendency (mean age) and the spread of ages among passengers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989fb1a1-b3d3-40b5-b67d-d2efd59cc2a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extracting the 'Age' column from the Titanic dataset\n",
    "ages = df['Age']\n",
    "\n",
    "# Plotting a histogram for Age\n",
    "plt.hist(ages, bins=10, edgecolor='k', alpha=0.7, color='skyblue')  # Create a histogram with 10 bins, edgecolor for bar borders, and alpha for transparency\n",
    "plt.title('Distribution of Passenger Ages')  # Set the title of the plot\n",
    "plt.xlabel('Age')  # Label the x-axis\n",
    "plt.ylabel('Frequency')  # Label the y-axis\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)  # Add a grid for better readability\n",
    "plt.axvline(ages.mean(), color='r', linestyle='dashed', linewidth=1, label='Mean Age')  # Add a vertical line for the mean age\n",
    "plt.legend(loc='upper right')  # Display the legend\n",
    "plt.show()  # Show the histogram plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdbaaa4-6adb-49cb-87f1-ac6cbf6ed775",
   "metadata": {},
   "source": [
    "## 4. Correlation and Heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885b96e-4470-42c5-a5eb-444c49a4a111",
   "metadata": {},
   "source": [
    "Correlation provides an understanding of how one variable changes concerning another. It is pivotal in understanding relationships between multiple variables in a dataset. A heatmap is an excellent tool to visually represent correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4ba0e-c397-4ff3-8a06-35633e6b144c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "# Draw a heatmap with the correlation values\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0d0bc-7b8d-491a-bfad-b3587f5b2ff0",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection and Handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dffa6c-3216-4856-9b02-73e621046512",
   "metadata": {},
   "source": [
    "Outliers are extreme values that may affect your analysis and statistical tests. Identifying and handling outliers is an essential step in EDA. A boxplot is a standardized way of displaying the distribution of data and can be used to detect outliers visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc81aa7-9c83-49ec-9fb6-fc4a63fe14e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting a boxplot for Age to detect outliers\n",
    "sns.boxplot(df['Age'])\n",
    "plt.title('Boxplot of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d48d2d-0faa-46b2-a877-bd5c5535b5bc",
   "metadata": {},
   "source": [
    "To identify and handle outliers in the `Age` feature:\n",
    "1. Identify outliers as values outside 1.5 times the IQR above Q3 or below Q1.\n",
    "2. Remove the identified outliers from the dataset.\n",
    "3. Visualize the updated box and whisker plot to confirm the changes.\n",
    "\n",
    "Here's how to do it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3da4f-44b2-42e2-9749-d9ee866f1077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Identify outliers\n",
    "Q1 = df['Age'].quantile(0.25)\n",
    "Q3 = df['Age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Step 2: Remove outliers\n",
    "df_cleaned = df[(df['Age'] >= lower_bound) & (df['Age'] <= upper_bound)]\n",
    "\n",
    "# Step 3: Visualize the updated box and whisker plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(df_cleaned['Age'])\n",
    "plt.title('Boxplot of Age (Outliers Removed)')\n",
    "plt.xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43704d0e-4c09-4975-8e9d-87ebb2275016",
   "metadata": {},
   "source": [
    "## 6. Handling Missing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017d466-5dea-4b82-b67a-04af3a2f8c49",
   "metadata": {},
   "source": [
    "Real-world data often has missing values. Handling missing data is essential to ensure your analyses are valid and conclusions are accurate. Data can be missing for various reasons, and the method to handle it depends on the nature of your data and the missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "adb38825-80c4-4913-aaa6-b578197881fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>51000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>62000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>57000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.0</td>\n",
       "      <td>59000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.0</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   Salary\n",
       "0  25.0  50000.0\n",
       "1  27.0  54000.0\n",
       "2  30.0      NaN\n",
       "3   NaN  58000.0\n",
       "4  24.0  51000.0\n",
       "5  31.0  62000.0\n",
       "6  34.0      NaN\n",
       "7  28.0  57000.0\n",
       "8  26.0  59000.0\n",
       "9  23.0  52000.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe with missing data for demonstration\n",
    "data_with_missing = {\n",
    "    'Age': [25, 27, 30, None, 24, 31, 34, 28, 26, 23],\n",
    "    'Salary': [50000, 54000, None, 58000, 51000, 62000, None, 57000, 59000, 52000]\n",
    "}\n",
    "df_missing = pd.DataFrame(data_with_missing)\n",
    "\n",
    "# Displaying the dataframe\n",
    "df_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34decd3f-908e-41c5-bd57-af96a24da9b1",
   "metadata": {},
   "source": [
    "Notice the `None` values in our dataset. These represent missing data. Let's check how many missing data points we have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "399d12e8-b9b9-4fd6-96d3-ce3d63adf913",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age       1\n",
       "Salary    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "missing_data = df_missing.isnull().sum()\n",
    "\n",
    "# Displaying missing data count\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315264af-8577-4254-9ad5-160129bd274b",
   "metadata": {},
   "source": [
    "Having missing data can cause a range of problems, from skewing statistical measures to rendering some algorithms inoperable. For instance, most machine learning algorithms require complete datasets to function correctly.\n",
    "\n",
    "Let's see two common strategies for handling missing data:\n",
    "\n",
    "1. Removing missing data entries.\n",
    "2. Imputing missing data based on other entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a1e7ebb6-b306-41b3-a818-e68568652f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>51000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.0</td>\n",
       "      <td>62000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>57000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.0</td>\n",
       "      <td>59000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.0</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age   Salary\n",
       "0  25.0  50000.0\n",
       "1  27.0  54000.0\n",
       "4  24.0  51000.0\n",
       "5  31.0  62000.0\n",
       "7  28.0  57000.0\n",
       "8  26.0  59000.0\n",
       "9  23.0  52000.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strategy 1: Removing missing data entries\n",
    "df_dropped = df_missing.dropna()\n",
    "\n",
    "# Displaying the dataframe after dropping missing values\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b97d2-3289-47f9-8784-3080d9c59a0c",
   "metadata": {},
   "source": [
    "Dropping missing values is straightforward, but it has its pitfalls. It can lead to loss of valuable data, especially if many rows contain at least one missing value. This can significantly reduce the sample size and potentially bias the analysis.\n",
    "\n",
    "Let's move on to the second strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d83e4046-3862-4b86-8195-43fe605bd1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>55375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.555556</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>51000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>62000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>55375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>57000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>59000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age   Salary\n",
       "0  25.000000  50000.0\n",
       "1  27.000000  54000.0\n",
       "2  30.000000  55375.0\n",
       "3  27.555556  58000.0\n",
       "4  24.000000  51000.0\n",
       "5  31.000000  62000.0\n",
       "6  34.000000  55375.0\n",
       "7  28.000000  57000.0\n",
       "8  26.000000  59000.0\n",
       "9  23.000000  52000.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strategy 2: Imputing missing data based on other entries\n",
    "# Here, we will use mean imputation as an example\n",
    "\n",
    "df_imputed = df_missing.copy()\n",
    "df_imputed['Age'].fillna(df_imputed['Age'].mean(), inplace=True)\n",
    "df_imputed['Salary'].fillna(df_imputed['Salary'].mean(), inplace=True)\n",
    "\n",
    "# Displaying the dataframe after imputation\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec701b-2b47-4675-a3bf-a7968234983b",
   "metadata": {},
   "source": [
    "Imputation replaces missing values with substituted values. The method of substitution can vary. We used the mean value of each column for our demonstration. Other methods include using the median, mode, or even sophisticated model-based methods.\n",
    "\n",
    "By handling the missing data, we've ensured that our dataset remains suitable for analysis and various algorithms. However, it's crucial to remember that the method used to handle missing data should align with the nature and reason for the missingness. Improper handling can introduce bias or inaccuracies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
